clean
cl
m(list = ls())
rm(li
st =
rm(list = ls())
graphics.off()
# clean console
cat("\014")
at("\01
library(dplyr) # librarfor cleaning datasets
library(stringr)
int("Hola
library(dplyr) # librarfor cleaning datasets
library(stringr)
#-----------------------------------------------------------------#
#Laboratorio 1 Python
print("Hola Mundo")
## Tipo de variable ####
a1 <- 3.1416
a1 <- 3.1416
print(a1)
typeof(a1)
class(a1)
is.numeric(a1)
a2 <- as.integer(a1)
typeof(a2)
class(a2)
is.numeric(a2)
b1 <- 10000
typeof(b1)
b1 <- as.integer(10000)
print(round(4.51))
install.packages("dplyr")
install.packages("stringr")
library(dplyr) # librarfor cleaning datasets
library(stringr)
str0 <- 'I love-Python and not R'
str1 <- strsplit(str0, ' ')
print(str1)
length(str1)
str1[[1][3]]
str1[[1]][3]
str1[[1]][4]
str1[[1]][2]
str1 <- strsplit(str0, ' ')
print(str1)
str2 <- strsplit(str0, split="[- ]")
print(str2)
str1 <- strsplit(str0, 'and')
print(str1)
str3 <- mishell
str3 <- 'mishell'
print(str3)
str1[[1]]= str3[2]
print[str1]
str3 <- strsplit(str0, split="[- ]")
print(str3)
str3 <- 'mishell'
print(str3)
str3 <- strsplit(str0, split="[- ]")
print(str3)
str3 <- 'mishell'
print(str3)
str3 <- strsplit(str0, split="[- ]")
print(str3)
str3 <- 'mishell'
print(str3)
str3 <- strsplit(str0, split="[- ]")
print(str3)
str3 <- 'mishell'
print(str3)
str3 <- strsplit(str0, split="[- ]")
print(str3)
str3 <- 'mishell'
print(str3)
str3 <- strsplit(str0, split="[- ]")
print(str3)
str1 <- strsplit(str0, 'and')
print(str1)
str2 <- strsplit(str0, split="[- ]")
print(str2)
str1 <- strsplit(str0, 'and')
print(str1)
str3 <- 'mishell'
print(str3)
str3 <- strsplit(str0, split="[and]")
print(str3)
str3 <- 'mishell'
print(str3)
str3 <- strsplit(str0, split="[and]")
print(str3)
str3 <- strsplit(str0, split="[- ]")
print(str3)
str1 <- strsplit(str3, split="[- ]")
print(str1)
str2[[2]]=str3[[1]]
print(str2)
str2 <- strsplit(str0, split="and")
print(str2)
str3 <- 'mishell'
print(str3)
#agregar
str2[[2]]=str3[[1]]
print(str2)
strsplit(str_trim(
str_to_upper(
gsub("[(|)|,]", "",string_4)
)
), " ")
string_4 <- ' (Hello World), '
str_trim(string_4) # by default clean empty at the ends
gsub("[(|)|,]", "",string_4)
str_trim(gsub("[(|)|,]", "",string_4)) # replace and trim
strsplit(str_trim(
str_to_upper(
gsub("[(|)|,]", "",string_4)
)
), " ")
var_list <- c('edad', 'gender', 'college', 'exp')
control_vars <- paste(var_list, collapse = "+")
print(control_vars)
print(control_vars)
print(var_list)
string_4 <- ' (Hello World), '
str_trim(string_4) # by default clean empty at the ends
gsub("[(|)|,]", "",string_4)
str_trim(gsub("[(|)|,]", "",string_4)) # replace and trim
help %>%
b1 <- "Facultad de Ciencias Sociales"
b2 <- '\ 2023'
d <- paste0(b1, b2)
print(d)
library(dplyr)
library(stringr)
-3.1416 %>% abs() %>% sqrt() %>% log() %>% round()
3.5 %>% as.integer ()
3.5 %>% round()
pi <--3.14 %>% abs()
pialcua <-- pi^2 # de esta manera se eleva al cuadrado
pientero <--pialcua  %>% log() %>% round()
# con round aproximamos al entero más cercano
pientero # ver el resultado
set.seed(756)
x1 <- runif(500)
x2 <- runif(500)
x3 <- runif(500)
x4 <- runif(500)
e <- rnorm(500)
Y <- 1 + 0.8*x1 + 1.2*x2 + 0.5*x3 + 1.5*x4 + e
Y <- 1 + 0.8*x1 + 1.2*x2 + 0.5*x3 + 1.5*x4 + e
matrix(1,500)
X <- cbind(matrix(1,500), x1,x2,x3,x4)
head(X)
X <- cbind(matrix(1,500), x1,x2,x3,x4)
head(X)
set.seed(756)
x1 <- runif(500)
x2 <- runif(500)
x3 <- runif(500)
x4 <- runif(500)
e <- rnorm(500)
# Poblacional regression (Data Generating Process GDP)
#estoy creando una función lineal
Y <- 1 + 0.8*x1 + 1.2*x2 + 0.5*x3 + 1.5*x4 + e
# y va a ser esta suma y productos de vectores
# ahora quiero estimar el beta
#beta = x'x
### primero crearé ese X grande
#M1 <- matrix(0,8,2)
X <- cbind(matrix(1,500), x1,x2,x3,x4)
head(X)
set.seed(756)
x1 <- runif(500)
x2 <- runif(500)
x3 <- runif(500)
x4 <- runif(500)
e <- rnorm(500)
# Poblacional regression (Data Generating Process GDP)
#estoy creando una función lineal
Y <- 1 + 0.8*x1 + 1.2*x2 + 0.5*x3 + 1.5*x4 + e
# y va a ser esta suma y productos de vectores
# ahora quiero estimar el beta
#beta = x'x
### primero crearé ese X grande
#M1 <- matrix(0,8,2)
X <- cbind(matrix(1,500), x1,x2,x3,x4)
head(X)
X <- cbind(matrix(1,500), x1,x2,x3,x4)
head(X)
X <- cbind(matrix(1,500)
matrix(1,500),
matrix(1,500)
matrix(1,500), x1,x2,x3,x4
cbind(matrix(1,500), x1,x2,x3,x4)
head(X)
beta <- solve(t(X) %*% X) %*% (t(X) %*% Y)
print(beta)
library(pacman)
library(pacman)
library(readxl)
library(dplyr)
library(rstudioapi) #
getwd()
y <- runif(10,-10,10)
if (mean(y) > 0) {
dummy <- 1
} else {
dummy <- 0
}
print(dummy)
y <- runif(10,-10,10) # runif( n: cantidad de elementos, inicio , final)
if (mean(y) > 0) {
dummy <- 1
} else {
dummy <- 0
}
print(dummy)
y <- runif(10,-10,10) # runif( n: cantidad de elementos, inicio , final)
if (mean(y) > 0) {
dummy <- 1
} else {
dummy <- 0
}
print(dummy)
rm(list = ls())
# Primero se cargan las librer?as
library(readxl)
library(dplyr)
library(rstudioapi)
library(readr)
mi_dataframe <- read_csv("BDD_compras_consumidores (1).csv")
# Escalar un vector de 100 números aleatorios
vector_aleatorio <- runif(100)
vector_escalamiento <- (vector_aleatorio - min(vector_aleatorio)) / (max(vector_aleatorio) - min(vector_aleatorio))
# Escalar todas las columnas numéricas de la base de datos
mi_dataframe_escalamiento <- as.data.frame(lapply(mi_dataframe, function(x) if(is.numeric(x)) (x - min(x)) / (max(x) - min(x)) else x))
# Ver los primeros registros de la base de datos escalada
head(mi_dataframe_escalamiento)
library(readxl)
library(dplyr)
library(rstudioapi)
library(readr)
mi_dataframe <- read_csv("BDD_compras_consumidores (1).csv")
# Leer el archivo CSV
mi_dataframe <- read_csv("C:\Users\MISHELL\Documents\GitHub\1ECO35_2023_1\data\BDD_compras_consumidores.csv")
Leer el archivo CSV
mi_dataframe <- read_csv("BDD_compras_consumidores.csv")
Leer el archivo CSV
mi_dataframe <- read_csv("BDD_compras_consumidores.csv")
View(mi_dataframe)
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", sep = ";")
rm(list = ls())
# Primero se cargan las librer?as
library(readxl)
library(dplyr)
library(rstudioapi)
library(readr)
# Leer el archivo CSV
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", sep = ";")
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", sep = ",")
datoscsv <- read.csv("../../data/Riesgo_morosidad.csv", sep = ";")
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", header = TRUE, sep = ",")
rm(list = ls())
# Primero se cargan las librer?as
library(readxl)
library(dplyr)
library(rstudioapi)
library(readr)
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", header = TRUE, sep = ",")
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", header = TRUE, sep = ",")
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", header = TRUE, sep = ",")
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", header = TRUE, sep = ",")
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", header = TRUE, sep = ",")
mi_dataframe <- read_csv("BDD_compras_consumidores.csv", delim = NULL)
mi_dataframe <- read_csv("BDD_compras_consumidores.csv")
View(mi_dataframe)
vector_aleatorio <- runif(100)
vector_escalamiento <- (vector_aleatorio - min(vector_aleatorio)) / (max(vector_aleatorio) - min(vector_aleatorio))
mi_dataframe_escalamiento <- as.data.frame(lapply(mi_dataframe, function(x) if(is.numeric(x)) (x - min(x)) / (max(x) - min(x)) else x))
head(mi_dataframe_escalamiento)
#Calcular la nota promedio final de cada alumno
siagie_promedio <- siagie %>%
mutate(promedio_final = rowMeans(.[7:ncol(.)], na.rm = TRUE))
mi_dataframe <- read_csv(BDD_compras_consumidores.csv)
rm(list = ls())
# Primero se cargan las librer?as
library(readxl)
library(dplyr)
library(rstudioapi)
library(readr)
# Leer el archivo CSV
mi_dataframe <- read_csv(BDD_compras_consumidores.csv)
rm(list = ls())
# Primero se cargan las librer?as
library(readxl)
library(dplyr)
library(rstudioapi)
library(readr)
# Leer el archivo CSV
mi_dataframe <- read_csv(BDD_compras_consumidores.csv)
mi_dataframe <- read_csv("BDD_compras_consumidores.csv")
head(mi_dataframe)
mi_dataframe <- read_csv("BDD_compras_consumidores.csv",
col_names = c('Channel','Region',
'Fresh', 'Milk', 'Grocery','Frozen'
, 'Detergents_paper','Delicatessen'))
rm(list = ls())
# Primero se cargan las librer?as
library(readxl)
library(dplyr)
library(rstudioapi)
library(readr)
mi_dataframe <- read_csv("BDD_compras_consumidores.csv",
col_names = c('Channel','Region',
'Fresh', 'Milk', 'Grocery','Frozen'
, 'Detergents_paper','Delicatessen'))
View(mi_dataframe)
head(mi_dataframe)
View(mi_dataframe)
vector_aleatorio <- runif(100)
vector_escalamiento <- (vector_aleatorio - min(vector_aleatorio)) / (max(vector_aleatorio) - min(vector_aleatorio))
head(vector_escalamiento)
head(vector_aleatorio)
rm(list = ls())
# Primero se cargan las librerias
library(readxl)
library(dplyr)
library(rstudioapi)
library(readr)
#1.
# Leer el archivo CSV
mi_dataframe <- read_csv("BDD_compras_consumidores.csv")
# Escalar un vector de 100 nÃºmeros aleatorios
vector_aleatorio <- runif(100)
vector_escalamiento <- (vector_aleatorio - min(vector_aleatorio)) / (max(vector_aleatorio) - min(vector_aleatorio))
# Escalar todas las columnas numÃ©ricas de la base de datos
mi_dataframe_escalamiento <- as.data.frame(lapply(mi_dataframe, function(x) if(is.numeric(x)) (x - min(x)) / (max(x) - min(x)) else x))
# Ver los primeros registros de la base de datos escalada
head(mi_dataframe_escalamiento)
#2.
siagie <- read.csv("siagie.csv")
library(dplyr)
#Calcular la nota promedio final de cada alumno
siagie_promedio <- siagie %>%
mutate(promedio_final = rowMeans(.[7:ncol(.)], na.rm = TRUE))
#hallar la nota maxima y minima
siagie_max <- siagie %>%
mutate(nota_max = apply(.[7:ncol(siagie)], 1, max, na.rm = TRUE))
siagie_min <- siagie %>%
mutate(nota_min = apply(.[7:ncol(siagie)], 1, min, na.rm = TRUE))
#hallar el promedio y mediana de notas de cada curso.
install.packages("tidyr")
library(tidyr)
siagie_promedio_curso <- siagie %>%
select(7:ncol(.)) %>%
pivot_longer(everything(), names_to = "curso", values_to = "nota") %>%
group_by(curso) %>%
summarize(promedio = mean(nota, na.rm = TRUE), mediana = median(nota, na.rm = TRUE))
siagie <- read.csv("siagie.csv")
siagie <- read.csv("siagie.csv")
siagie <- read.csv("siagie.csv")
siagie <- read.csv("siagie.csv")
library(tidyr)
library(dplyr)
siagie_promedio <- siagie %>%
mutate(promedio_final = rowMeans(.[7:ncol(.)], na.rm = TRUE))
#hallar la nota maxima y minima
siagie_max <- siagie %>%
mutate(nota_max = apply(.[7:ncol(siagie)], 1, max, na.rm = TRUE))
siagie_min <- siagie %>%
mutate(nota_min = apply(.[7:ncol(siagie)], 1, min, na.rm = TRUE))
#
siagie_promedio_curso <- siagie %>%
select(7:ncol(.)) %>%
pivot_longer(everything(), names_to = "curso", values_to = "nota") %>%
group_by(curso) %>%
summarize(promedio = mean(nota, na.rm = TRUE), mediana = median(nota, na.rm = TRUE))
View(siagie_promedio_curso)
View(siagie_promedio)
View(siagie_min)
View(siagie_max)
View(siagie)
################  Laboratorio 11 parte 4 ------------------------
## Curso: Laboratorio de R y Python ###########################
## @author: Roberto Mendoza
# clean environment variables
rm(list = ls())
# clean plots
graphics.off()
# clean console
cat("\014")
# additional options
options(scipen = 999)      # No scientific notation
options(warn = -1)
# Library ####
# Load libraries ----
library(pacman)
p_load(
tidyverse
, raster
, sf
, rgdal
)
#Set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#------------------------------------------------------------#
dpt_shp <- st_read(
'../../data/geopandas_data/LIMITE_DEPARTAMENTO/LIMITE_DEP.shp'
)
dpt_shp$Point_centroid <-st_centroid(dpt_shp)['geometry']
# coordenadas en columnas separadas
dpt_shp$longitude <- st_coordinates(dpt_shp$Point_centroid)[, 1]
dpt_shp$latitude <- st_coordinates(dpt_shp$Point_centroid)[, 2]
#-----------------------------------------------------------#
# plot raster file
tavg <- raster(
"../../data/geopandas_data/tavg.tif"
) |>
rasterToPoints() |>  # coordenadas por raster, se toma el promedio de la variable en el pixel
data.frame() |>
as_tibble() |>
rename(fill1 = 3)
ggplot() +
geom_raster(data = tavg, aes(x, y, fill = fill1))
################  Laboratorio 11 parte 4 ------------------------
## Curso: Laboratorio de R y Python ###########################
## @author: Roberto Mendoza
# clean environment variables
rm(list = ls())
# clean plots
graphics.off()
# clean console
cat("\014")
# additional options
options(scipen = 999)      # No scientific notation
options(warn = -1)
# Library ####
# Load libraries ----
library(pacman)
p_load(
tidyverse
, raster
, sf
, rgdal
)
#Set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#------------------------------------------------------------#
dpt_shp <- st_read(
'../../data/geopandas_data/LIMITE_DEPARTAMENTO/LIMITE_DEP.shp'
)
dpt_shp$Point_centroid <-st_centroid(dpt_shp)['geometry']
# coordenadas en columnas separadas
dpt_shp$longitude <- st_coordinates(dpt_shp$Point_centroid)[, 1]
dpt_shp$latitude <- st_coordinates(dpt_shp$Point_centroid)[, 2]
#-----------------------------------------------------------#
# plot raster file
tavg <- raster(
"../../data/geopandas_data/tavg.tif"
) |>
rasterToPoints() |>  # coordenadas por raster, se toma el promedio de la variable en el pixel
data.frame() |>
as_tibble() |>
rename(fill1 = 3)
ggplot() +
geom_raster(data = tavg, aes(x, y, fill = fill1))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
################  Laboratorio 11 parte 4 ------------------------
## Curso: Laboratorio de R y Python ###########################
## @author: Roberto Mendoza
# clean environment variables
rm(list = ls())
# clean plots
graphics.off()
# clean console
cat("\014")
# additional options
options(scipen = 999)      # No scientific notation
options(warn = -1)
# Library ####
# Load libraries ----
library(pacman)
p_load(
tidyverse
, raster
, sf
, rgdal
)
#Set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#------------------------------------------------------------#
dpt_shp <- st_read(
'../../data/geopandas_data/LIMITE_DEPARTAMENTO/LIMITE_DEP.shp'
)
dpt_shp$Point_centroid <-st_centroid(dpt_shp)['geometry']
# coordenadas en columnas separadas
dpt_shp$longitude <- st_coordinates(dpt_shp$Point_centroid)[, 1]
dpt_shp$latitude <- st_coordinates(dpt_shp$Point_centroid)[, 2]
#-----------------------------------------------------------#
# plot raster file
tavg <- raster(
"../../data/geopandas_data/tavg.tif"
) |>
rasterToPoints() |>  # coordenadas por raster, se toma el promedio de la variable en el pixel
data.frame() |>
as_tibble() |>
rename(fill1 = 3)
ggplot() +
geom_raster(data = tavg, aes(x, y, fill = fill1))
