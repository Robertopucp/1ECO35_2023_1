{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usa estas opciones con su respectivo orden:\n",
      "\n",
      ">>>scraper_contraloria('Region','Responsabilidad','Periodo')\n",
      ">>>scraper_contraloria('Region','Responsabilidad')\n",
      ">>>scraper_contraloria('Region')'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from pandas import ExcelWriter\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def scraper_contraloria(region,responsabilidad='example,',periodo='example'):\n",
    "    try:\n",
    "        options = webdriver.ChromeOptions()\n",
    "#         driver = webdriver.Chrome(ChromeDriverManager().install(),options=options)\n",
    "\n",
    "        driver_path = './chromedriver_win32/chromedriver.exe'\n",
    "        driver = webdriver.Chrome(driver_path,options=options)\n",
    "        driver.get('https://appbp.contraloria.gob.pe/BuscadorCGR/Informes/Avanzado.html')\n",
    "        driver.maximize_window()\n",
    "\n",
    "        # Convertimos las alternativas ingresadas en mayusculas(es asi como lo ubicaremos en el Dom):\n",
    "        region           = region.upper()\n",
    "        responsabilidad  = responsabilidad.upper()\n",
    "\n",
    "        # Damos click en Responsabilidad, segun la alternativa ingresada.\n",
    "        try:\n",
    "            personas_cpr = driver.find_element_by_xpath('//*[@id=\"lblResponsabilidad\"]//ul')\n",
    "            personas_cpr.location_once_scrolled_into_view\n",
    "            personas_cp  = personas_cpr.find_element_by_partial_link_text(responsabilidad)\n",
    "            personas_cp.click()\n",
    "        except:\n",
    "            print('\\nResponsabilidad no especificada.\\nSe an procesado todas las responsabilidades.\\n')\n",
    "\n",
    "        # Tal ves ingresan la opcion 'P. C. DEL CALLAO' sin los puntos, aca los colocamos para ubicarlo en el Dom.\n",
    "        if region == 'P C DEL CALLAO':\n",
    "            region = 'P. C. DEL CALLAO'\n",
    "        else: \n",
    "            pass\n",
    "        # Damos click en la region ingresada, con 2 intentos:\n",
    "        try:\n",
    "        # si la opción ingresada(REGION) esta ubicada en la ventana por defecto, con estas 4 lineas bastara.\n",
    "            continuo_link = driver.find_element_by_xpath('//*[@id=\"lblRegion\"]/ul')\n",
    "            continuo_link.location_once_scrolled_into_view\n",
    "            continue_link = continuo_link.find_element_by_partial_link_text(region)\n",
    "            continue_link.click()\n",
    "        except:\n",
    "        # amos click en 'VER MAS' para extender las opciones.\n",
    "            element = driver.find_element_by_xpath('//*[@id=\"lblRegion\"]/ul/li[4]/label')\n",
    "            element.location_once_scrolled_into_view\n",
    "            element.click()\n",
    "\n",
    "        # Ahora podremos ubicar nuestra opcion ingresada(REGION) le damos click.\n",
    "            continuo_link = driver.find_element_by_xpath('//*[@id=\"lblRegion\"]/ul/li[4]/div/ul')\n",
    "            continue_link = continuo_link.find_element_by_partial_link_text(region)#aqui\n",
    "            continue_link.location_once_scrolled_into_view\n",
    "            continue_link.click()\n",
    "\n",
    "        # Escogemos 'MUNICIPALIDADES DISTRITALES' esta opción estara marcada por defecto en nuestro codigo.\n",
    "        element = driver.find_element_by_xpath('//*[@id=\"lblSector\"]/ul/li[1]/a/label/p')\n",
    "        element.location_once_scrolled_into_view\n",
    "        element.click()\n",
    "\n",
    "        # Seleccionamos 'Periodo de emisión del informe' solo si se ah ingresado una opción.\n",
    "        try:\n",
    "            try:\n",
    "            # si la opción ingresada(Periodo) esta ubicada en la ventana por defecto, con estas 4 lineas bastara.\n",
    "                periods = driver.find_element_by_xpath('//*[@id=\"lblPeriodo\"]/ul')\n",
    "                periods.location_once_scrolled_into_view\n",
    "                perio = periods.find_element_by_partial_link_text(periodo)#aqui\n",
    "                perio.click()\n",
    "            except:\n",
    "            # Damos click en 'VER MAS' para extender las opciones.\n",
    "                element = driver.find_element_by_xpath('//*[@id=\"lblPeriodo\"]/ul/li[4]/label')\n",
    "                element.location_once_scrolled_into_view\n",
    "                element.click()\n",
    "\n",
    "            # Ahora podremos ubicar nuestra opcion ingresada(Periodo) le damos click.\n",
    "                periods = driver.find_element_by_xpath('//*[@id=\"lblPeriodo\"]/ul')\n",
    "                periods.location_once_scrolled_into_view\n",
    "                perio = periods.find_element_by_partial_link_text(periodo)#aqui\n",
    "                perio.click()\n",
    "        except:\n",
    "            print('Periodo sin especificar.\\n\\nSe an procesado todos los Periodos. ')\n",
    "\n",
    "        # Limpiamos las palabras(opciones) ingresadas para poder transcribirlas en las carpetas que se crearan despues.\n",
    "        region = region.replace(' ','_')\n",
    "        if '.' in region:\n",
    "            region = region.replace('.','')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "       # Creamos Carpeta 'scraper_contraloria'.\n",
    "        try:\n",
    "            os.mkdir('scraper_contraloria')\n",
    "        except:\n",
    "            pass\n",
    "        # Creamos carpeta segun la opción(REGION) dentro de 'scraper_contraloria'.\n",
    "        try:\n",
    "            os.mkdir(os.path.join('scraper_contraloria',region))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Cambiamos la opcion que determina la cantidad de documentos por pagina, de '10' a '100'.\n",
    "\n",
    "        dropdown = Select(driver.find_element_by_id('listaCantidadRegistros'))\n",
    "        dropdown.select_by_visible_text('100')\n",
    "\n",
    "\n",
    "        # Creamos listas vacias para trabajar los loops.\n",
    "\n",
    "        regions                                        =      []\n",
    "        tipo_de_servicio                               =      []\n",
    "        num_de_inf                                     =      []\n",
    "        entidad                                        =      []\n",
    "        titulo_del_informe                             =      []\n",
    "        evento                                         =      []\n",
    "        operativo                                      =      []\n",
    "        n_de_p_c_p_r                                   =      []\n",
    "        tipo_de_responsabilidad                        =      []\n",
    "        fecha_de_emision                               =      []\n",
    "        fecha_de_publicacion                           =      []\n",
    "        link_de_ficha_de_resumen                       =      []\n",
    "        link_de_informe                                =      []\n",
    "        anexos                                         =      []\n",
    "\n",
    "        # En el traspié de la página nos indica la cantidad de páginas, lo usamos para iterar el for loop.\n",
    "        next_page = driver.find_element_by_xpath('//*[@id=\"lbltotalItems\"]').text\n",
    "        next_page = next_page.split('de ')[1]\n",
    "        next_page = int(next_page)\n",
    "        # Iteramos.\n",
    "        try:\n",
    "            for i in range(0,next_page,1):\n",
    "                x = 1\n",
    "                zzz = '1' \n",
    "                while zzz != 0:\n",
    "                        reg          = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[1]').text]\n",
    "                        tip_de_serv  = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[2]').text]\n",
    "                        num_d_inf    = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[3]').text]\n",
    "                        ent          = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[4]').text]\n",
    "                        tit_d_i      = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[5]').text]\n",
    "                        ev           = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[6]').text]\n",
    "                        op           = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[7]').text]\n",
    "                        n_d_p_c_p_r  = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[8]').text]\n",
    "                        t_d_r        = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[9]').text]\n",
    "                        f_d_e        = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[10]').text]\n",
    "                        f_d_p        = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[11]').text]\n",
    "                        link_d_f_d_r = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[12]//a').get_attribute(\"href\")]\n",
    "                        link_d_i     = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[13]//a').get_attribute(\"href\")]\n",
    "                        anx          = [driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x}]/td[14]').text]\n",
    "                        try:\n",
    "                            driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{x+1}]/td[10]')\n",
    "                        except:\n",
    "                            zzz = 0\n",
    "                        x += 1\n",
    "                        # Llenamos las listas vacias de arriva con datos por iteración.\n",
    "\n",
    "                        regions                                        += reg\n",
    "                        tipo_de_servicio                               += tip_de_serv\n",
    "                        num_de_inf                                     += num_d_inf\n",
    "                        entidad                                        += ent\n",
    "                        titulo_del_informe                             += tit_d_i\n",
    "                        evento                                         += ev\n",
    "                        operativo                                      += op\n",
    "                        n_de_p_c_p_r                                   += n_d_p_c_p_r\n",
    "                        tipo_de_responsabilidad                        += t_d_r\n",
    "                        fecha_de_emision                               += f_d_e\n",
    "                        fecha_de_publicacion                           += f_d_p\n",
    "                        link_de_ficha_de_resumen                       += link_d_f_d_r\n",
    "                        link_de_informe                                += link_d_i\n",
    "                        anexos                                         += anx \n",
    "\n",
    "                # A 'region' le cambiamos los 'espacios' por 'guiones bajos' para una correcta escritura en las carpetas.\n",
    "                region = region.replace(' ','_')###DATO EXTRA:si deseas solo el excel,comenta desde aqui hasta ....(lineas 177-247)\n",
    "                \n",
    "                # A 'region' Si tuviera 'puntos' seran borrados.\n",
    "                if '.' in region:\n",
    "                    region = region.replace('.','')\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                # A los 'número de informe' les reemplazamos caracteres extraños, para poder renombrar las carpetas y sus archivos pdf.                fold  = list( map(lambda x:x.replace('/',  '_'), num_de_inf ) )\n",
    "                folde = list( map(lambda x:x.replace('\\\\', '_'), fold       ) )\n",
    "                # Creamos las carpetas donde se ubicarán los pdf.\n",
    "                for q in folde:\n",
    "                    try:\n",
    "                        os.mkdir(os.path.join('scraper_contraloria',region,q))\n",
    "                    except:\n",
    "                        pass\n",
    "                # Utilizamos un 'while loop' para descargar los '-resumen.pdf'.\n",
    "                m = 1\n",
    "                g = 'g'\n",
    "                while g != 0:\n",
    "                    num_d_in   = driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{m}]/td[3]').text\n",
    "                    link_d_f   = driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{m}]/td[12]//a').get_attribute(\"href\")\n",
    "                # Al los 'numero de informe' les reemplazamos caracteres extraños, para poder renombrar los '-resumen.pdf'.\n",
    "                    fold  =  num_d_in.replace('/','_')\n",
    "                    folde =  fold.replace('\\\\','_')\n",
    "                # Descargamos los 'resumen pdf', si no existe una descarga(mantenimiento de página) pasara a la siguiente descarga.\n",
    "                    try:\n",
    "                        url  = link_d_f\n",
    "                        file =  os.path.join(os.getcwd(),'scraper_contraloria',region,folde,folde+'-resumen.pdf')\n",
    "\n",
    "                        r = urllib.request.urlopen(url)\n",
    "                        f = open(file,\"wb\")\n",
    "\n",
    "                        f.write(r.read())\n",
    "                        f.close()\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{m+1}]/td[3]')\n",
    "                    except:\n",
    "                        g = 0\n",
    "                    m += 1\n",
    "                    \n",
    "                # Utilizamos un 'while loop' para descargar los '-informe.pdf'.\n",
    "                m = 1\n",
    "                g = 'g'\n",
    "                while g != 0:\n",
    "                    num_d_in   = driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{m}]/td[3]').text\n",
    "                    link_d_i   = driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{m}]/td[13]//a').get_attribute(\"href\")\n",
    "                # Al los 'numero de informe' les reemplazamos caracteres extraños, para poder renombrar los '-informe.pdf'.\n",
    "                    fold  =  num_d_in.replace('/','_')\n",
    "                    folde =  fold.replace('\\\\','_')\n",
    "                # Descargamos los 'informe pdf', si no existe una descarga(mantenimiento de página o etc) pasara a la siguiente descraga.\n",
    "                    try:\n",
    "                        url  = link_d_i\n",
    "                        file =  os.path.join(os.getcwd(),'scraper_contraloria',region,folde,folde+'-informe.pdf')\n",
    "\n",
    "                        r = urllib.request.urlopen(url)\n",
    "                        f = open(file,\"wb\")\n",
    "\n",
    "                        f.write(r.read())\n",
    "                        f.close()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        driver.find_element_by_xpath(f'//*[@id=\"tablaResultadosUltimosInformes\"]/tbody/tr[{m+1}]/td[3]')\n",
    "                    except:\n",
    "                        g = 0\n",
    "                    m += 1  ### DATO EXTRA: ...comenta hasta aqui! para solo recibir el excel (lineas 177-246)\n",
    "                #Damos click en 'Siguiente' para continuar con el loop en la siguiente pagina solo si ubiese.\n",
    "                try:\n",
    "                    driver.find_element_by_xpath('//*[@id=\"Li_Siguiente\"]/a').click()\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            print('0 documentos encontrados')\n",
    "            \n",
    "    # Colocamos como string los números de 'número de personas con presunta responsabilidad' para centrarlos en la tabla del Excel.\n",
    "        num_de_personas_con_presunta_responsabilidad = list( map(lambda x: x.rjust(40), n_de_p_c_p_r  ) )\n",
    "\n",
    "        #Creamos el indice.\n",
    "        indices = []\n",
    "        for i in range(1,len(regions)+1):\n",
    "            indices.append(i)\n",
    "        # Creamos el Excel.\n",
    "        df = pd.DataFrame({'Region':regions,\n",
    "                         'Tipo_de_Servicio':tipo_de_servicio,\n",
    "                         'N_de_Informe':num_de_inf,\n",
    "                         'Entidad':entidad,\n",
    "                         'Título_del_Informe':titulo_del_informe,\n",
    "                         'Evento':evento,\n",
    "                         'Operativo':operativo,\n",
    "                         'N_Personas_co_Presunta_Responsabilidad':num_de_personas_con_presunta_responsabilidad,\n",
    "                         'Tipo_de_Responsabilidad':tipo_de_responsabilidad,\n",
    "                         'Fecha_Emisión':fecha_de_emision,\n",
    "                         'Fecha_Publicación':fecha_de_publicacion,\n",
    "                         'Ficha_Resumen':link_de_ficha_de_resumen,\n",
    "                         'Informes':link_de_informe,\n",
    "                         'Anexos':anexos},index=indices)\n",
    "        writer = ExcelWriter(os.path.join(os.getcwd(),'scraper_contraloria',region,f'{region}.xlsx'))\n",
    "        df.to_excel(writer,f'{region}.xlsx')\n",
    "        writer.save()\n",
    "    except:\n",
    "        driver.quit()\n",
    "print(\"Usa estas opciones con su respectivo orden:\\n\\n>>>scraper_contraloria('Region','Responsabilidad','Periodo')\\n\\\n",
    ">>>scraper_contraloria('Region','Responsabilidad')\\n>>>scraper_contraloria('Region')'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n",
      "Periodo sin especificar.\n",
      "\n",
      "Se an procesado todos los Periodos. \n"
     ]
    }
   ],
   "source": [
    "OPCIONES   =        ['LIMA', 'ANCASH', 'CUSCO', 'AREQUIPA', 'LA LIBERTAD', 'CAJAMARCA', 'PIURA',\n",
    "                     'JUNIN', 'PUNO', 'AYACUCHO', 'LORETO', 'P. C. DEL CALLAO', 'LAMBAYEQUE', 'ICA',\n",
    "                     'SAN MARTIN', 'HUANUCO', 'TACNA','HUANCAVELICA', 'UCAYALI', 'APURIMAC', 'AMAZONAS',\n",
    "                     'TUMBES', 'MOQUEGUA', 'MADRE DE DIOS', 'PASCO']\n",
    "\n",
    "for OPCION in OPCIONES:\n",
    "    \n",
    "    scraper_contraloria(OPCION,'penal')\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper_contraloria('lima','administrativo')\n",
    "scraper_contraloria('PUNO','PENAL','2020')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
